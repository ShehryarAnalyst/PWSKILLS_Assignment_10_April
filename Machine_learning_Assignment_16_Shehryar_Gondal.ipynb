{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "582f3832",
   "metadata": {},
   "source": [
    "## Assignment Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac8e975",
   "metadata": {},
   "source": [
    "__Q1. What is Bayes' theorem?__\n",
    "\n",
    "__Ans)__ Bayes' theorem is a fundamental concept in probability theory and statistics that describes the relationship between conditional probabilities. It is named after Thomas Bayes, an English mathematician and theologian.\n",
    "\n",
    "Bayes' theorem mathematically expresses how our beliefs or knowledge about an event can be updated in light of new evidence. It states that the probability of an event A given the occurrence of an event B is equal to the probability of event B given event A, multiplied by the prior probability of event A, divided by the prior probability of event B. In mathematical notation, Bayes' theorem can be represented as:\n",
    "\n",
    "- P(A|B) = [P(B|A) * P(A)] / P(B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e976d142",
   "metadata": {},
   "source": [
    "__Q2. What is the formula for Bayes' theorem?__\n",
    "\n",
    "__Ans)__  Bayes' theorem is a fundamental principle in Bayesian inference. It states the relationship between the conditional probabilities of two events. The formula for Bayes' theorem is:\n",
    "\n",
    "- P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "- P(A|B) is the probability of event A given that event B has occurred (the posterior probability).\n",
    "- P(B|A) is the probability of event B given that event A has occurred (the likelihood).\n",
    "- P(A) is the probability of event A occurring (the prior probability).\n",
    "- P(B) is the probability of event B occurring.\n",
    "\n",
    "__In Bayesian inference, we use Bayes' theorem to update our belief (the prior probability) about the occurrence of an event, given new evidence (the likelihood) obtained from observed data.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d21929",
   "metadata": {},
   "source": [
    "__Q3. How is Bayes' theorem used in practice?__\n",
    "\n",
    "__Ans)__ Bayes' theorem is used in practice to update probabilities or beliefs about events based on new evidence. It involves assigning prior probabilities, collecting data, defining the likelihood function, and applying Bayes' theorem to obtain updated probabilities. The results are interpreted to make informed decisions. The process can be iterative as new data becomes available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32321f43",
   "metadata": {},
   "source": [
    "__Q4. What is the relationship between Bayes' theorem and conditional probability?__\n",
    "\n",
    "__Ans)__ Bayes' theorem provides a mathematical relationship between conditional probabilities. It relates the probability of an event A given that event B has occurred (P(A|B)) to the probability of event B given that event A has occurred (P(B|A)). The formula for Bayes' theorem is as follows:\n",
    "\n",
    "- P(A|B) = (P(B|A) * P(A)) / P(B)\n",
    "\n",
    "In this formula, P(A|B) represents the conditional probability of event A given event B, P(B|A) represents the conditional probability of event B given event A, P(A) represents the prior probability of event A, and P(B) represents the prior probability of event B.\n",
    "\n",
    "__Bayes' theorem allows us to update our beliefs or probabilities about event A based on new evidence or information provided by event B. It provides a systematic way of incorporating new data into our existing knowledge to revise and calculate the conditional probabilities.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b573b0",
   "metadata": {},
   "source": [
    "__Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?__\n",
    "\n",
    "__Ans)__ When choosing the type of Naive Bayes classifier to use for a given problem, several factors should be considered:\n",
    "\n",
    "1. Nature of the features: Naive Bayes classifiers assume that features are conditionally independent given the class label. Therefore, the choice of classifier should align with the nature of the features.\n",
    "\n",
    "- For binary or categorical features, the Multinomial Naive Bayes classifier is commonly used.\n",
    "- For continuous or numerical features, the Gaussian Naive Bayes classifier is often appropriate.\n",
    "- For features that follow a multinomial distribution (e.g., word frequencies in text classification), the Multinomial Naive Bayes classifier is suitable.\n",
    "\n",
    "2. Distribution of the data: Consider the distribution of the data and whether it aligns with the assumptions of the Naive Bayes classifiers.\n",
    "\n",
    "- Gaussian Naive Bayes assumes that the features follow a Gaussian distribution.\n",
    "- Multinomial Naive Bayes assumes that the features have a multinomial distribution.\n",
    "\n",
    "3. Size of the dataset: Naive Bayes classifiers tend to work well even with small amounts of data, as they have low computational complexity. However, if the dataset is large, the computational efficiency of the classifier may become a consideration.\n",
    "\n",
    "4. Evaluation metrics: Consider the evaluation metrics that are important for your problem. Each type of Naive Bayes classifier may have different performance characteristics depending on the nature of the data and the problem at hand. It's important to assess the classifiers' performance using appropriate evaluation metrics (e.g., accuracy, precision, recall, F1-score) and choose the one that performs best for your specific problem.\n",
    "\n",
    "__Ultimately, the choice of Naive Bayes classifier should be based on an understanding of the problem, the nature of the data, and the specific requirements and constraints of the task. It is often recommended to experiment with different types of Naive Bayes classifiers and evaluate their performance to determine the most suitable one for your particular problem.__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07702b99",
   "metadata": {},
   "source": [
    "__Q6. Assignment:\n",
    "You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c877e5",
   "metadata": {},
   "source": [
    "To predict the class of the new instance using Naive Bayes, we need to calculate the posterior probabilities for each class and choose the class with the highest probability.\n",
    "\n",
    "Given that we have equal prior probabilities for each class, the prior probabilities are P(A) = 0.5 and P(B) = 0.5.\n",
    "\n",
    "To calculate the likelihoods, we count the frequencies of each feature value for each class:\n",
    "\n",
    "For Class A:\n",
    "P(X1=3|A) = 4 / 16 = 0.25\n",
    "P(X2=4|A) = 3 / 16 = 0.1875\n",
    "\n",
    "For Class B:\n",
    "P(X1=3|B) = 1 / 10 = 0.1\n",
    "P(X2=4|B) = 3 / 10 = 0.3\n",
    "\n",
    "Now, we can calculate the posterior probabilities using Bayes' theorem:\n",
    "\n",
    "P(A|X1=3, X2=4) = (P(X1=3|A) * P(X2=4|A) * P(A)) / P(X1=3, X2=4)\n",
    "P(B|X1=3, X2=4) = (P(X1=3|B) * P(X2=4|B) * P(B)) / P(X1=3, X2=4)\n",
    "\n",
    "Since P(X1=3, X2=4) is the same for both classes and we only need to compare the ratios of the probabilities, we can ignore the denominator.\n",
    "\n",
    "Calculating the posterior probabilities:\n",
    "\n",
    "P(A|X1=3, X2=4) = (0.25 * 0.1875 * 0.5) = 0.0234375\n",
    "P(B|X1=3, X2=4) = (0.1 * 0.3 * 0.5) = 0.015\n",
    "\n",
    "Comparing the posterior probabilities, we can see that P(A|X1=3, X2=4) > P(B|X1=3, X2=4).\n",
    "\n",
    "Therefore, Naive Bayes would predict the new instance to belong to Class A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9316718",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
